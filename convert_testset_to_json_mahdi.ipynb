{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Reciept Data\n",
    "The code cell below will parse all of the txt files in ./testset/txt and save the JSON results in ./testset/json with the same filename as the txt file except the .json extention instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "#### MODEL ####\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# jnicolwathawiiAPIkey = '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'\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "#### Prompt ####\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "import time\n",
    "\n",
    "# get examples\n",
    "examples = []\n",
    "jsonFiles = glob(os.path.join(os.path.join('data', 'receipts', 'json', 'actual'), '*.json'))\n",
    "for jsonFile in jsonFiles:\n",
    "    baseFn = os.path.basename(jsonFile.replace('.json', ''))\n",
    "    txtFile = glob(os.path.join('data', 'receipts', 'text', f'{baseFn}.txt'))[0]\n",
    "    with open(jsonFile, 'r') as f: JSONobj = f.read()\n",
    "    with open(txtFile, 'r') as f: rawRecieptText = f.read()\n",
    "    exampleDict = {\n",
    "        \"rawRecieptText\": rawRecieptText,\n",
    "        \"JSONobj\":JSONobj.replace('{', '{{{{').replace('}', '}}}}')\n",
    "        }\n",
    "    examples.append(exampleDict)\n",
    "\n",
    "\n",
    "promptTemplateFile = os.path.join('receipt_parse', 'prompt_templates', 'prompt_template_2.txt')\n",
    "with open(promptTemplateFile, 'r') as f: promptTemplate = f.read()\n",
    "example_prompt = PromptTemplate(input_variables=[\"rawRecieptText\", \"JSONobj\"], \n",
    "                            template=promptTemplate)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=[examples[0]],\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Get JSON for this:\\n{input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "#   print(prompt.format(input=\"recieptTxt\"))\n",
    "\n",
    "\n",
    "\n",
    "#### Create Chain ####\n",
    "chain = prompt | model # how to pass the prompt to the model (pipe prompt to model)\n",
    "\n",
    "#### Run inference on reciepts ####\n",
    "promptName = os.path.basename(promptTemplateFile).split('.txt')[0].replace('_', '')#.split('_')[-1] e.g. prompt_template_1\n",
    "recieptFiles = glob(os.path.join('testset', 'txt' '*.txt'))\n",
    "for recieptFn in recieptFiles:\n",
    "    print(recieptFn)\n",
    "    saveJson = os.path.join('testset', 'json', f'{os.path.basename(recieptFn).split(\".tx\")[0]}.json')\n",
    "    if os.path.exists(saveJson):continue\n",
    "    with open(recieptFn, 'r') as f: recieptTxt = f.read()\n",
    "    try:\n",
    "        response = chain.invoke({'input': recieptTxt})\n",
    "    except:\n",
    "        time.sleep(20) # assume its a RateLimitError\n",
    "        response = chain.invoke({'input': recieptTxt})\n",
    "\n",
    "    # print(response)\n",
    "    try:\n",
    "        data_dict = json.loads(response.content)\n",
    "    except(json.decoder.JSONDecodeError):\n",
    "        print(response.content)\n",
    "    else:\n",
    "        with open(saveJson, 'w') as f: json.dump(data_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nervaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vender (merchant) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Random Forest Model Accuracy: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_read_file(file_path):\n",
    "    encodings = ['utf-8', 'latin-1', 'windows-1252']  # Add more if needed\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as file:\n",
    "                return json.load(file)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"File {file_path} has an unknown encoding.\")\n",
    "\n",
    "def json_to_string(data):\n",
    "    data_copy = data.copy()\n",
    "    data_copy['ReceiptInfo'].pop('merchantCategory', None)\n",
    "    return json.dumps(data_copy, sort_keys=True)\n",
    "\n",
    "# Path to the JSON files\n",
    "json_folder_path = 'data/receipts/json/prompt2'\n",
    "\n",
    "# Collect data for training\n",
    "data = {'file_name': [], 'vendor_name': [], 'json_string': [], 'category': []}\n",
    "\n",
    "# Iterate over JSON files\n",
    "for file_name in os.listdir(json_folder_path):\n",
    "    file_path = os.path.join(json_folder_path, file_name)\n",
    "    try:\n",
    "        data_json = try_read_file(file_path)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    merchant_category = data_json['ReceiptInfo'].get('merchantCategory')\n",
    "    \n",
    "    if not merchant_category:\n",
    "        continue\n",
    "\n",
    "    merchant_name = data_json['ReceiptInfo'].get('merchant', 'Unknown')\n",
    "    json_string = json_to_string(data_json)\n",
    "    data['file_name'].append(file_name)\n",
    "    data['vendor_name'].append(merchant_name)\n",
    "    data['json_string'].append(json_string)\n",
    "    data['category'].append(merchant_category)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=3, ngram_range=(1, 3), stop_words='english')\n",
    "X = vectorizer.fit_transform(df['json_string'])\n",
    "y = df['category']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, min_samples_leaf=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Model Accuracy: {accuracy_rf}\")\n",
    "\n",
    "# Predict and save results for all data\n",
    "all_predictions = rf_model.predict(X)\n",
    "results = pd.DataFrame({'Category': all_predictions, 'Vendor Name': df['vendor_name'], 'File Name':  df['file_name']})\n",
    "results.sort_values(by=['Category', 'Vendor Name'], inplace=True)\n",
    "results.to_csv('vendor_classification_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Classification\n",
    "The code cell below will create a pkl file for each receipt JSON file which is a list of each of the item categories. The file has the same name and location as the JSON file but has the extention .pkl instead of .json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "prompt_str=\"\"\"\n",
    "Can you return the item category of the items. Just return one word which is one of the categories below that best fits the item.\n",
    "Food: example dairy, sports drinks, eggs\n",
    "Medicine: example cough drops\n",
    "House supplies: building material and tools as well as house hold supplies\n",
    "Hobbies: Sports, video games etc\n",
    "\n",
    "Here is the item info:\n",
    "{itemdata}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "chain = prompt | model # how to pass the prompt to the model (pipe prompt to model)\n",
    "\n",
    "\n",
    "for jsonFile in glob(os.path.join('testset', 'json', '*.json')):\n",
    "    pickle_file = os.path.join('testset', 'json', base_name + '_itemclasses.pkl')\n",
    "    if os.path.exists(pickle_file): continue\n",
    "    with open(jsonFile, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    itemCats = []\n",
    "    for item in data['ReceiptInfo']['ITEMS']:\n",
    "        itemCats.append(chain.invoke({'itemdata':str(item)}).content)\n",
    "        try:\n",
    "            itemCats.append(chain.invoke({'itemdata':str(item)}).content)\n",
    "        except:\n",
    "            time.sleep(40) # assume its a RateLimitError\n",
    "            itemCats.append(chain.invoke({'itemdata':str(item)}).content)\n",
    "\n",
    "    base = os.path.basename(jsonFile)\n",
    "    base_name = os.path.splitext(base)[0].split('_')[0]\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(itemCats, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
